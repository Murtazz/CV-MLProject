{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Murtaza Khalid\n",
        "\n",
        "Email: khal3470@mylaurier.ca\n",
        "\n",
        "Project Title: Predicting the Possibility of Cardiovascular Disease in Patients Under 70 \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bdpVRHCyRsDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I - Main Project"
      ],
      "metadata": {
        "id": "rPJSRJ1EO128"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwUhOVjkozGs"
      },
      "source": [
        "## 1 - Import Dependencies and Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OiNmcMXpAC8"
      },
      "source": [
        "Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mfo-I4Fa3Mo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import confusion_matrix,classification_report, roc_auc_score, RocCurveDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import validation_curve\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x12pvqgopMA7"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7eR3wBChGTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "82ff1884-4d97-48cd-e375-2b16e8e58c81"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3199de95a6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morig_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/heart.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# making a mutable copy of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/heart.csv'"
          ]
        }
      ],
      "source": [
        "orig_data = pd.read_csv(\"/content/heart.csv\")\n",
        "# making a mutable copy of the dataset\n",
        "ds = orig_data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGdW2FOpXmH"
      },
      "source": [
        "## 2 - Visualizing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozbMU9NkhOV7"
      },
      "outputs": [],
      "source": [
        "# testing if imported correctly - print first 5 rows\n",
        "ds.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZHuvkeXiHTl"
      },
      "outputs": [],
      "source": [
        "# check the number of rows/columns in ds\n",
        "ds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv9LzUO1iQ6T"
      },
      "outputs": [],
      "source": [
        "# check the types of the columns and if there is any null values\n",
        "ds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlizzfAfLFPS"
      },
      "outputs": [],
      "source": [
        "# null-value count\n",
        "ds.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWh9BejyLdrX"
      },
      "outputs": [],
      "source": [
        "# stat measures of ds\n",
        "ds.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRhEtxXtNwNk"
      },
      "outputs": [],
      "source": [
        "HD = ds[\"HeartDisease\"].value_counts()\n",
        "print(HD)\n",
        "keys = [\"Heart Disease\", \"Normal\"]\n",
        "count = [HD[1], HD[0]]\n",
        "plt.bar(keys, count, width=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pBlTazkassX"
      },
      "outputs": [],
      "source": [
        "# Male/Female HeartDisease distribution\n",
        "def O1_to_YS(s):\n",
        "  if s == 0:\n",
        "    return \"N\"\n",
        "  elif s == 1:\n",
        "    return \"Y\"\n",
        "\n",
        "plot_ds = ds\n",
        "plot_ds[\"HeartDiseaseYN\"] = ds['HeartDisease'].apply(O1_to_YS)\n",
        "sns.histplot(data=plot_ds, x=\"HeartDiseaseYN\", hue=\"Sex\", multiple=\"dodge\")\n",
        "ds = ds.drop(columns = \"HeartDiseaseYN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFD8UGByY9fd"
      },
      "outputs": [],
      "source": [
        "#Age distribution\n",
        "sns.histplot(data=ds, x=\"Age\", stat=\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL5ErkK-f5f0"
      },
      "outputs": [],
      "source": [
        "data = ds.groupby('ChestPainType').count()\n",
        "data.head()\n",
        "plt.pie(data = data, x=\"Age\", labels = [\"ASY\", \"ATA\", \"NAP\", \"TA\"], autopct='%.1f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_37Y7TdclyOa"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=ds, x=\"ChestPainType\", hue=\"HeartDisease\", multiple=\"dodge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ7DuE-zmXlj"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=ds, x=\"Cholesterol\", hue=\"HeartDisease\", stat=\"count\", multiple=\"stack\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnFSRDD2po_1"
      },
      "source": [
        "## 3 - Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEsL0VIVpxPm"
      },
      "source": [
        "Turn strings -> integer form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTt8FS1BihkD"
      },
      "outputs": [],
      "source": [
        "# ChestPainType -> Int\n",
        "def CPT_to_number(s):\n",
        "  if s == \"TA\":\n",
        "    return 0\n",
        "  elif s == \"ATA\":\n",
        "    return 1\n",
        "  elif s == \"NAP\":\n",
        "    return 2\n",
        "  elif s == \"ASY\":\n",
        "    return 3\n",
        "\n",
        "# M (Male) or F (Female) -> Int\n",
        "def MF_to_number(s):\n",
        "  if s == \"M\":\n",
        "    return 0\n",
        "  elif s == \"F\":\n",
        "    return 1\n",
        "\n",
        "# Y (Yes) or N (No) -> Int\n",
        "def YN_to_number(s):\n",
        "  if s == \"N\":\n",
        "    return 0\n",
        "  elif s == \"Y\":\n",
        "    return 1\n",
        "\n",
        "# Normal or ST or LVH -> Int\n",
        "def NS_to_number(s):\n",
        "  if s == \"Normal\":\n",
        "    return 0\n",
        "  elif s == \"ST\":\n",
        "    return 1\n",
        "  elif s == \"LVH\":\n",
        "    return 2\n",
        "\n",
        "# Up or Flat or Down -> Int\n",
        "def UFD_to_number(s):\n",
        "  if s == \"Up\":\n",
        "    return 0\n",
        "  elif s == \"Flat\":\n",
        "    return 1\n",
        "  elif s == \"Down\":\n",
        "    return 2\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RONSsApsMLtt"
      },
      "outputs": [],
      "source": [
        "# apply the string to integer functions\n",
        "ds['ChestPainTypePos'] = ds['ChestPainType'].apply(CPT_to_number)\n",
        "ds['SexPos'] = ds['Sex'].apply(MF_to_number)\n",
        "ds['ExerciseAnginaPos'] = ds['ExerciseAngina'].apply(YN_to_number)\n",
        "ds['RestingECGPos'] = ds['RestingECG'].apply(NS_to_number)\n",
        "ds['ST_SlopePos'] = ds['ST_Slope'].apply(UFD_to_number)\n",
        "\n",
        "#Drop all string columns\n",
        "ds = ds.drop(columns = \"ExerciseAngina\")\n",
        "ds = ds.drop(columns = \"Sex\")\n",
        "ds = ds.drop(columns = \"ChestPainType\")\n",
        "ds = ds.drop(columns = \"RestingECG\")\n",
        "ds = ds.drop(columns = \"ST_Slope\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlR31gBzaGiv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,6))\n",
        "colors = ['#ea230c','#ffe599', '#b2ff03']\n",
        "sns.heatmap(ds.corr(),cmap = colors,annot = True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_SN2H3kbGxD"
      },
      "outputs": [],
      "source": [
        "corr = ds.corrwith(ds['HeartDisease']).sort_values(ascending = False).to_frame()\n",
        "corr.columns = ['Correlations']\n",
        "plt.subplots(figsize = (5,5))\n",
        "sns.heatmap(corr,annot = True,cmap = colors,linewidths = 0.4,linecolor = 'black');\n",
        "plt.title('Correlation with HeartDisease');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQL9tkpqQqK"
      },
      "source": [
        "Remove outliers found while visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y47ce1agAN9"
      },
      "outputs": [],
      "source": [
        "# RestingECGPos has 0.061 correlation to HeartDisease so it will be dropped\n",
        "ds = ds.drop(columns = \"RestingECGPos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJA7uML2q5VZ"
      },
      "source": [
        "Split Features (X) and Label (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU_Y-bW57n6y"
      },
      "outputs": [],
      "source": [
        "X = ds.drop(columns=\"HeartDisease\")\n",
        "y = ds[\"HeartDisease\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3piHyBklzoxq"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIm4K07G2l1O"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoOX9eyqTew0"
      },
      "source": [
        "## 4 - Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7uLPZaZ6b7q"
      },
      "outputs": [],
      "source": [
        "models_used = []\n",
        "test_acc_results = []\n",
        "train_acc_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onufXri8ueVu"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B36tkfzYbGyZ"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rS2ZR6xEmkx"
      },
      "source": [
        "Functions Used for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlDSPTl9tilz"
      },
      "outputs": [],
      "source": [
        "# Learning Curve\n",
        "def lcurve(mod_class, X, y):\n",
        "  \n",
        "  train_sizes, train_scores, test_scores = learning_curve(mod_class, X, y, cv=10, scoring ='accuracy',\n",
        "  train_sizes=np.linspace(.1, 1.0, 10))\n",
        "\n",
        "  # Create mean of train and test scores\n",
        "  train_mean = np.mean(train_scores, axis=1)\n",
        "  test_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "  # Plot learning curve lines (mean of training and test scores)\n",
        "  plt.plot(train_sizes, train_mean, '--',  label=\"Training score\")\n",
        "  plt.plot(train_sizes, test_mean,  label=\"Cross-validation score\")\n",
        "\n",
        "  # Add title and labels and show the plot\n",
        "  plt.title(\"Learning Curve\")\n",
        "  plt.xlabel(\"Training Set Size\")\n",
        "  plt.ylabel(\"Accuracy Score\")\n",
        "  plt.legend(loc=\"best\")\n",
        "  plt.yticks(np.arange(0.75, 1.0, 0.025))\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODsmKSvot0Ks"
      },
      "outputs": [],
      "source": [
        "# Validation Curve\n",
        "def vcurve(mod_class, X, y):\n",
        "\n",
        "  # Define the range of parameter to be tested\n",
        "  param_range = np.arange(0.1,10,0.1)\n",
        "  \n",
        "  # Calculate accuracy on training and test set using range of parameter values\n",
        "  train_scores, test_scores = validation_curve(mod_class, X, y, param_name=\"C\", param_range=param_range, cv=5, scoring=\"accuracy\")\n",
        "\n",
        "  # Calculate mean for training and test scores\n",
        "  train_mean = np.mean(train_scores, axis=1)\n",
        "  test_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "  # Plot validation curve lines (mean of training and test scores)\n",
        "  plt.plot(param_range, train_mean, '--',label=\"Training score\")\n",
        "  plt.plot(param_range, test_mean, label=\"Cross-validation score\")\n",
        "\n",
        "  # Add title and labels and show the plot\n",
        "  plt.title(\"Validation Curve\")\n",
        "  plt.ylim([0.75, 1.0])\n",
        "  plt.xlabel(\"Value of regularization term\")\n",
        "  plt.ylabel(\"Accuracy Score\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XuStuIjOhO1"
      },
      "outputs": [],
      "source": [
        "# Cross-Validation\n",
        "def cv_measure(mod_class, X, y, k=10): # default k = 10\n",
        "  mod_class.fit(X, y)\n",
        "\n",
        "  print(\"K=10 Fold Cross Validation:\")\n",
        "  # Perform cross-validation with K=10 (cv=10) and \"accuracy\" as performance measure\n",
        "  cv_results = cross_validate(mod_class, X, y, cv=k, scoring ='accuracy')\n",
        "  \n",
        "  # Store results\n",
        "  cv_scores = cv_results['test_score'] \n",
        "\n",
        "  # Print cross-validation results\n",
        "  print(\"Cross-validation score for each of the folds: \", [float('{:.3f}'.format(x)) for x in cv_scores])\n",
        "  print(\"Mean cross-validation score (or cross-validation score): %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZivfYzP6l7xV"
      },
      "outputs": [],
      "source": [
        "def model_measure(mod_class):\n",
        "  # Train(fit) model\n",
        "  mod_class.fit(X_train,y_train)\n",
        "  #print(mod_class.kneighbors)\n",
        "  y_train_predict = mod_class.predict(X_train)\n",
        "  y_test_predict = mod_class.predict(X_test)\n",
        " \n",
        "  # Count percentage of correct predictions\n",
        "  print(\"The performance of the model:\")\n",
        "  print(\"（づ￣3￣）づ╭❤️～(⓿_⓿)\")\n",
        "  print(\"The Log Loss of the model:\")\n",
        "  print('Log loss of the model for training set: %.3f' % log_loss(y_train,y_train_predict))\n",
        "  print('Log loss of the model for test set: %.3f' % log_loss(y_test,y_test_predict))\n",
        "  print(\"--------------------------------------\")\n",
        "\n",
        "  cv_measure(mod_class, X, y)\n",
        "  print(\"--------------------------------------\")\n",
        "\n",
        "  print(\"Accuracy:\")\n",
        "  # Performance of the model\n",
        "  print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train,y_train_predict))\n",
        "  print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test,y_test_predict))\n",
        "\n",
        "  print(\"--------------------------------------\")\n",
        "\n",
        "  print(\"Confusion Matrix:\")\n",
        "\n",
        "  # Confusion matrix\n",
        "  sns.heatmap(confusion_matrix(y_test, y_test_predict),annot=True, fmt = 'g')\n",
        "\n",
        "  return accuracy_score(y_train,y_train_predict), accuracy_score(y_test,y_test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BXAQfveTbXj"
      },
      "source": [
        "### A - Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkf5STA0udZH"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXHZaHPvT-gg"
      },
      "outputs": [],
      "source": [
        "# Build a logstic regression object\n",
        "LogReg = LogisticRegression(solver = 'newton-cg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLNovYwoHXU8"
      },
      "outputs": [],
      "source": [
        "models_used.append('Logistic Regression')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYJrzAZnUAKU"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(LogReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHrVnQdj7qQJ"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npFn-pDPwF2q"
      },
      "outputs": [],
      "source": [
        "# Learning Curve\n",
        "lcurve(LogReg, X_train, y_train)\n",
        "  \n",
        "# Validation Curve \n",
        "vcurve(LogReg, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgeDlbyOVfgG"
      },
      "source": [
        "### B - KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLuAAS12a1r9"
      },
      "outputs": [],
      "source": [
        "#Trial and error for KNN - result 18\n",
        "\"\"\"def model_measure_trials(mod_class):\n",
        "  # Train(fit) model\n",
        "  mod_class.fit(X_train,y_train)\n",
        "  #print(mod_class.kneighbors)\n",
        "  y_train_predict = mod_class.predict(X_train)\n",
        "  y_test_predict = mod_class.predict(X_test)\n",
        "  \n",
        "  return accuracy_score(y_test,y_test_predict)\n",
        "\n",
        "best = 0\n",
        "j = 1\n",
        "num = 1\n",
        "while j != 100:\n",
        "  knn_test = KNeighborsClassifier(n_neighbors = j)\n",
        "  n = model_measure_trials(knn_test)\n",
        "  if n > best:\n",
        "    best = n\n",
        "    num = j\n",
        "  j += 1\n",
        "print(best)\n",
        "print(num)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF98xR_oVhsj"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZibpRp6HcV0"
      },
      "outputs": [],
      "source": [
        "models_used.append('KNN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jppqiaXX1Tg"
      },
      "source": [
        "Training and testing KNN Model using data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvl7MiWjRo85"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 85/15: 85% for training and 15% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zHzvgezVnxu"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ghA969xHNV-"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAeWEot1wOpV"
      },
      "outputs": [],
      "source": [
        "# Learning Curve\n",
        "lcurve(knn, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RtCHdk7-fhk"
      },
      "source": [
        "### C - SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3snVBDz-Wsq"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn0nyx63P5cm"
      },
      "outputs": [],
      "source": [
        "for kernel in ['linear', 'poly', 'rbf']:\n",
        "  classifier = svm.SVC(gamma=0.001, kernel=kernel)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_train_predict = classifier.predict(X_train)\n",
        "  y_test_predict = classifier.predict(X_test)\n",
        "  print('For kerenl {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "\n",
        "  print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train_predict, y_train))\n",
        "  print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCalOxKW0Dui"
      },
      "source": [
        "Hyper-Parameter Tuning for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX28wFwt0HeU"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters || not picking poly due to significantly low accuracy than the rest\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['linear', 'rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM7yNjL90bls"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=svm.SVC(), param_grid=param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-txCltVAj9H"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL8at80l24g7"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMIwmsmp6VF0"
      },
      "source": [
        "Optimal SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe4gac4k5x7j"
      },
      "outputs": [],
      "source": [
        "classifier = svm.SVC(gamma=0.001, kernel='linear', C=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE-DU5o4H3uY"
      },
      "outputs": [],
      "source": [
        "models_used.append('SVM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nBnYfXl8Ga5"
      },
      "outputs": [],
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "y_train_predict = classifier.predict(X_train)\n",
        "y_test_predict = classifier.predict(X_test)\n",
        "\n",
        "print('For kernel {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZiwzO40HFD7"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict),3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Curve\n",
        "lcurve(classifier, X_train, y_train)"
      ],
      "metadata": {
        "id": "FzA8XHTSuSmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-btMjib-mb6"
      },
      "source": [
        "### D - Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8jNpaJc9qlK"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6AZcYUl-yGd"
      },
      "outputs": [],
      "source": [
        "# RF model with all 10 features\n",
        "rf = RandomForestClassifier(max_features=10, n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68bVtvh9_Bkz"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woxBqWwy_WWO"
      },
      "outputs": [],
      "source": [
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VqiHJwP_2lt"
      },
      "source": [
        "Hyper-Parameter Tuning for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmRga9cp_vco"
      },
      "outputs": [],
      "source": [
        "max_features_range = np.arange(1,11,1)\n",
        "n_estimators_range = np.arange(10,210,10)\n",
        "param_grid = {'max_features': max_features_range, 'n_estimators': n_estimators_range}\n",
        "\n",
        "grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct9pO6DeAZwC"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1mJnHm3AbHR"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUEpv2Q6Byli"
      },
      "source": [
        "Optimal Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i5qrWCeBvah"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_features=1, n_estimators=170)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnaLshdyHCNU"
      },
      "outputs": [],
      "source": [
        "models_used.append('Random Forest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R37LLZKoCBoH"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUnY9LvLHASS"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict), 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Curve\n",
        "lcurve(rf, X_train, y_train)"
      ],
      "metadata": {
        "id": "LyPYkT4quhfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uejLF9iSHICF"
      },
      "source": [
        "### E - Model Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmK3CsdS8KiJ"
      },
      "outputs": [],
      "source": [
        "mods = np.array(models_used)\n",
        "train = np.array(train_acc_results)\n",
        "test = np.array(test_acc_results)\n",
        "accu_ds = pd.DataFrame({'Classifiers': mods, 'Train Accuracy': train, 'Test Accuracy': test}, columns=['Classifiers', 'Train Accuracy', 'Test Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf3thR9-87fD"
      },
      "outputs": [],
      "source": [
        "accu_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O98EJAHFIJE"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Train Accuracy']\n",
        "\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Training Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Training Accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWLqhi4XNZGO"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Test Accuracy']\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Testing Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Testing Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXSVBe4qodzI"
      },
      "source": [
        "# II - Using Object Only Features to Predict the Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6FAiFYLo5aS"
      },
      "outputs": [],
      "source": [
        "orig_data = pd.read_csv(\"/content/heart.csv\")\n",
        "# making a mutable copy of the dataset\n",
        "ds2 = orig_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKUgNxzRA2_q"
      },
      "outputs": [],
      "source": [
        "models_used = []\n",
        "test_acc_results = []\n",
        "train_acc_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vILmkSs24w4x"
      },
      "outputs": [],
      "source": [
        "# Drop all integer/float based features\n",
        "ds2 = ds2.drop(columns = [\"Age\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"Oldpeak\"])\n",
        "# Drop RestingECG as correlation is very low\n",
        "ds2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU4UJgV9_Jlm"
      },
      "outputs": [],
      "source": [
        "X = ds2.drop(columns=\"HeartDisease\")\n",
        "y = ds2[\"HeartDisease\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpOy9KbqC5zh"
      },
      "source": [
        "Convert strings to numerics for "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFLJJc32B0k3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(X)\n",
        "X = encoder.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6-dcaq6DJ5P"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9_DFfKO_LzI"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPFSrxd3AO3n"
      },
      "outputs": [],
      "source": [
        "# Build a logstic regression object\n",
        "LogReg = LogisticRegression(solver = 'newton-cg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYH4RvNEAsx7"
      },
      "outputs": [],
      "source": [
        "models_used.append('Logistic Regression')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HsInUpyA6AQ"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(LogReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdAo_IN8CMH3"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBliKrRcCQAe"
      },
      "outputs": [],
      "source": [
        "# Learning Curve\n",
        "lcurve(LogReg, X_train, y_train)\n",
        "  \n",
        "# Validation Curve \n",
        "vcurve(LogReg, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF6mB_3vDqSg"
      },
      "source": [
        "## KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80lSF0nuDvxl"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 85/15: 85% for training and 15% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9rXjy8fEJzR"
      },
      "outputs": [],
      "source": [
        "#Trial and error for KNN - result 17\n",
        "\"\"\"def model_measure_trials(mod_class):\n",
        "  # Train(fit) model\n",
        "  mod_class.fit(X_train,y_train)\n",
        "  #print(mod_class.kneighbors)\n",
        "  y_train_predict = mod_class.predict(X_train)\n",
        "  y_test_predict = mod_class.predict(X_test)\n",
        "  \n",
        "  return accuracy_score(y_test,y_test_predict)\n",
        "\n",
        "best = 0\n",
        "j = 1\n",
        "num = 1\n",
        "while j != 100:\n",
        "  knn_test = KNeighborsClassifier(n_neighbors = j)\n",
        "  n = model_measure_trials(knn_test)\n",
        "  if n > best:\n",
        "    best = n\n",
        "    num = j\n",
        "  j += 1\n",
        "print(best)\n",
        "print(num)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2zmGxFpD-Kn"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8lvdkXAD5Ki"
      },
      "outputs": [],
      "source": [
        "models_used.append('KNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnxF5wU_JhtE"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc-UYh7xJdPy"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_vMfggoFOgx"
      },
      "source": [
        "## SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC9vhn2zFafy"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iB_MvPXFafy"
      },
      "outputs": [],
      "source": [
        "for kernel in ['linear', 'poly', 'rbf']:\n",
        "  classifier = svm.SVC(gamma=0.001, kernel=kernel)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_train_predict = classifier.predict(X_train)\n",
        "  y_test_predict = classifier.predict(X_test)\n",
        "  print('For kerenl {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "\n",
        "  print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train_predict, y_train))\n",
        "  print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-DtBQ2QFafy"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters || not picking poly due to significantly low accuracy than the rest\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['linear', 'rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OyIwMXKFafz"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=svm.SVC(), param_grid=param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9R4Xq1TFafz"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSFMisDMFafz"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2L8C0XxFafz"
      },
      "outputs": [],
      "source": [
        "classifier = svm.SVC(gamma=0.001, kernel='linear', C=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo0t4KJwFafz"
      },
      "outputs": [],
      "source": [
        "models_used.append('SVM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnB-jz6xFafz"
      },
      "outputs": [],
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "y_train_predict = classifier.predict(X_train)\n",
        "y_test_predict = classifier.predict(X_test)\n",
        "\n",
        "print('For kernel {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq1QWFNVFafz"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS5FHNLXFq6m"
      },
      "source": [
        "## Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNRkYwmiF5wF"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F2x5U3XF5wF"
      },
      "outputs": [],
      "source": [
        "# RF model with all 10 features\n",
        "rf = RandomForestClassifier(max_features=10, n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ldw-pRzqF5wF"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6z3s2v-F5wG"
      },
      "outputs": [],
      "source": [
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_gGOMXiF5wG"
      },
      "outputs": [],
      "source": [
        "max_features_range = np.arange(1,11,1)\n",
        "n_estimators_range = np.arange(10,210,10)\n",
        "param_grid = {'max_features': max_features_range, 'n_estimators': n_estimators_range}\n",
        "\n",
        "grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgJbWsHEF5wG"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inOh9vQRF5wG"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrGMyhunF5wG"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_features=8, n_estimators=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N_0m68HF5wG"
      },
      "outputs": [],
      "source": [
        "models_used.append('Random Forest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIe7YwC0F5wG"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQLR6mqQF5wG"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oXupOAfHSZu"
      },
      "source": [
        "## Model Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6D3dTApHWXm"
      },
      "outputs": [],
      "source": [
        "mods = np.array(models_used)\n",
        "train = np.array(train_acc_results)\n",
        "test = np.array(test_acc_results)\n",
        "accu_ds = pd.DataFrame({'Classifiers': mods, 'Train Accuracy': train, 'Test Accuracy': test}, columns=['Classifiers', 'Train Accuracy', 'Test Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WTNCgZoHWXm"
      },
      "outputs": [],
      "source": [
        "accu_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J4qOkhuHWXm"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Train Accuracy']\n",
        "\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Training Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Training Accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3epKJEZrHWXm"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Test Accuracy']\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Testing Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Testing Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVG2-8Eko9jB"
      },
      "source": [
        "# III - Using Numeric Only Features to Predict the Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29UbMF8_KNre"
      },
      "outputs": [],
      "source": [
        "orig_data = pd.read_csv(\"/content/heart.csv\")\n",
        "# making a mutable copy of the dataset\n",
        "ds3 = orig_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A7OfkQWKNrf"
      },
      "outputs": [],
      "source": [
        "models_used = []\n",
        "test_acc_results = []\n",
        "train_acc_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYls5pC_KNrf"
      },
      "outputs": [],
      "source": [
        "# Drop all string columns\n",
        "ds3 = ds3.drop(columns = \"ExerciseAngina\")\n",
        "ds3 = ds3.drop(columns = \"Sex\")\n",
        "ds3 = ds3.drop(columns = \"ChestPainType\")\n",
        "ds3 = ds3.drop(columns = \"RestingECG\")\n",
        "ds3 = ds3.drop(columns = \"ST_Slope\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xyacADMKNrf"
      },
      "outputs": [],
      "source": [
        "X = ds3.drop(columns=\"HeartDisease\")\n",
        "y = ds3[\"HeartDisease\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrQ1rgqEpCHm"
      },
      "outputs": [],
      "source": [
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHn_N6QSLq-k"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfOFdEg1Lq-l"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOBRHJ8fLq-l"
      },
      "outputs": [],
      "source": [
        "# Build a logstic regression object\n",
        "LogReg = LogisticRegression(solver = 'newton-cg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR7beVeGLq-l"
      },
      "outputs": [],
      "source": [
        "models_used.append('Logistic Regression')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82_kKT9dLq-l"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(LogReg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlgmlCyfLq-l"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ_zGHUALq-m"
      },
      "outputs": [],
      "source": [
        "# Learning Curve\n",
        "lcurve(LogReg, X_train, y_train)\n",
        "  \n",
        "# Validation Curve \n",
        "vcurve(LogReg, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAjTUk8Lq-m"
      },
      "source": [
        "## KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOwpkw-TLq-m"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 85/15: 85% for training and 15% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1tyYTttLq-m"
      },
      "outputs": [],
      "source": [
        "#Trial and error for KNN - result 18\n",
        "\"\"\"def model_measure_trials(mod_class):\n",
        "  # Train(fit) model\n",
        "  mod_class.fit(X_train,y_train)\n",
        "  #print(mod_class.kneighbors)\n",
        "  y_train_predict = mod_class.predict(X_train)\n",
        "  y_test_predict = mod_class.predict(X_test)\n",
        "  \n",
        "  return accuracy_score(y_test,y_test_predict)\n",
        "\n",
        "best = 0\n",
        "j = 1\n",
        "num = 1\n",
        "while j != 100:\n",
        "  knn_test = KNeighborsClassifier(n_neighbors = j)\n",
        "  n = model_measure_trials(knn_test)\n",
        "  if n > best:\n",
        "    best = n\n",
        "    num = j\n",
        "  j += 1\n",
        "print(best)\n",
        "print(num)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flYPrYybLq-m"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqXMpxhqLq-m"
      },
      "outputs": [],
      "source": [
        "models_used.append('KNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdY-_y3cLq-m"
      },
      "outputs": [],
      "source": [
        "train_acc, test_acc = model_measure(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L1Okkq4Lq-n"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(train_acc, 3))\n",
        "test_acc_results.append(round(test_acc, 3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Curve\n",
        "lcurve(knn, X_train, y_train)"
      ],
      "metadata": {
        "id": "sVZI6RpOMaR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-LHlEdFLq-n"
      },
      "source": [
        "## SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g423vCKMLq-n"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPVAni8LLq-n"
      },
      "outputs": [],
      "source": [
        "for kernel in ['linear', 'poly', 'rbf']:\n",
        "  classifier = svm.SVC(gamma=0.001, kernel=kernel)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_train_predict = classifier.predict(X_train)\n",
        "  y_test_predict = classifier.predict(X_test)\n",
        "  print('For kerenl {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "\n",
        "  print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train_predict, y_train))\n",
        "  print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdXX7JROLq-n"
      },
      "outputs": [],
      "source": [
        "# Hyper Parameters || not picking poly due to significantly low accuracy than the rest\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['linear', 'rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMTAWQmCLq-n"
      },
      "outputs": [],
      "source": [
        "grid = GridSearchCV(estimator=svm.SVC(), param_grid=param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToSEBdm7Lq-n"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9E8sX00Lq-o"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iXXj5kILq-o"
      },
      "outputs": [],
      "source": [
        "classifier = svm.SVC(gamma=0.001, kernel='linear', C=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuX2CmLoLq-o"
      },
      "outputs": [],
      "source": [
        "models_used.append('SVM')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E5xD29wLq-o"
      },
      "outputs": [],
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "y_train_predict = classifier.predict(X_train)\n",
        "y_test_predict = classifier.predict(X_test)\n",
        "\n",
        "print('For kernel {} the f1 score is: {}'.format(kernel, metrics.f1_score(y_test, y_test_predict, average='micro')))\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXjRTt9kLq-o"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C13yT8fdLq-o"
      },
      "source": [
        "## Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtXMi96YLq-o"
      },
      "outputs": [],
      "source": [
        "#split training and test data: 80/20: 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGAX8MIALq-o"
      },
      "outputs": [],
      "source": [
        "# RF model with all 10 features\n",
        "rf = RandomForestClassifier(max_features=5, n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYDCdPEyLq-p"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iypCW85LLq-p"
      },
      "outputs": [],
      "source": [
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjrvbjAJLq-p"
      },
      "outputs": [],
      "source": [
        "max_features_range = np.arange(1,11,1)\n",
        "n_estimators_range = np.arange(10,210,10)\n",
        "param_grid = {'max_features': max_features_range, 'n_estimators': n_estimators_range}\n",
        "\n",
        "grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96bUsyjfLq-p"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzbj2E3eLq-p"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)\n",
        "print(grid.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnMdqTSrLq-p"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(max_features=1, n_estimators=130)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGLcLqsjLq-p"
      },
      "outputs": [],
      "source": [
        "models_used.append('Random Forest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKurjTtjLq-p"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_train_predict = rf.predict(X_train)\n",
        "y_test_predict = rf.predict(X_test)\n",
        "\n",
        "print('Accuracy of the model for training set: %.3f' % accuracy_score(y_train, y_train_predict))\n",
        "print('Accuracy of the model for test set: %.3f' % accuracy_score(y_test, y_test_predict))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dfF-FfnLq-q"
      },
      "outputs": [],
      "source": [
        "train_acc_results.append(round(accuracy_score(y_train_predict, y_train), 3))\n",
        "test_acc_results.append(round(accuracy_score(y_test, y_test_predict), 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0xQp1qMLq-q"
      },
      "source": [
        "## Model Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM126yg-Lq-q"
      },
      "outputs": [],
      "source": [
        "mods = np.array(models_used)\n",
        "train = np.array(train_acc_results)\n",
        "test = np.array(test_acc_results)\n",
        "accu_ds = pd.DataFrame({'Classifiers': mods, 'Train Accuracy': train, 'Test Accuracy': test}, columns=['Classifiers', 'Train Accuracy', 'Test Accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-eLe4g-Lq-q"
      },
      "outputs": [],
      "source": [
        "accu_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lL_toROLq-q"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Train Accuracy']\n",
        "\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Training Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Training Accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCevrIrmLq-q"
      },
      "outputs": [],
      "source": [
        "accx = accu_ds['Classifiers']\n",
        "accy = accu_ds['Test Accuracy']\n",
        "plt.bar(accx, accy, color=['red', 'green', 'blue', 'cyan'])\n",
        "for i in range(len(accx)):\n",
        "  plt.text(i, accy[i], accy[i], ha=\"center\")\n",
        "\n",
        "plt.title('Model Testing Accuracy')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Testing Accuracy')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D-btMjib-mb6",
        "GXSVBe4qodzI",
        "w6-dcaq6DJ5P",
        "GF6mB_3vDqSg",
        "z_vMfggoFOgx",
        "JS5FHNLXFq6m",
        "1oXupOAfHSZu",
        "RVG2-8Eko9jB",
        "DHn_N6QSLq-k",
        "FIAjTUk8Lq-m",
        "K-LHlEdFLq-n",
        "C13yT8fdLq-o",
        "x0xQp1qMLq-q"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}